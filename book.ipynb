{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c9d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse, mae\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68abeb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings\n",
      "   userId  movieId  rating        date      time\n",
      "0       1        1     4.0  2000-07-30  18:45:03\n",
      "1       1        3     4.0  2000-07-30  18:20:47\n",
      "2       1        6     4.0  2000-07-30  18:37:04\n",
      "3       1       47     5.0  2000-07-30  19:03:35\n",
      "4       1       50     5.0  2000-07-30  18:48:51\n",
      "movies\n",
      "   movieId                              title \n",
      "0        1                    Toy Story (1995)\n",
      "1        2                      Jumanji (1995)\n",
      "2        3             Grumpier Old Men (1995)\n",
      "3        4            Waiting to Exhale (1995)\n",
      "4        5  Father of the Bride Part II (1995)\n",
      "tags\n",
      "   userId  movieId              tag        date      time\n",
      "0       2    60756            funny  2015-10-24  19:29:54\n",
      "1       2    60756  Highly quotable  2015-10-24  19:29:56\n",
      "2       2    60756     will ferrell  2015-10-24  19:29:52\n",
      "3       2    89774     Boxing story  2015-10-24  19:33:27\n",
      "4       2    89774              MMA  2015-10-24  19:33:20\n",
      "links\n",
      "   movieId  imdbId  tmdbId\n",
      "0        1  114709     862\n",
      "1        2  113497    8844\n",
      "2        3  113228   15602\n",
      "3        4  114885   31357\n",
      "4        5  113041   11862\n",
      "movie_genre\n",
      "   movieId  genreId      genre\n",
      "0        1        0  Adventure\n",
      "1        1        1  Animation\n",
      "2        1        2  Children \n",
      "3        1        3     Comedy\n",
      "4        1        4    Fantasy\n",
      "genre\n",
      "   genreId      genre\n",
      "0        0  Adventure\n",
      "1        1  Animation\n",
      "2        2   Children\n",
      "3        3     Comedy\n",
      "4        4    Fantasy\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "movies  = pd.read_csv(\"data/movies.csv\")\n",
    "tags    = pd.read_csv(\"data/tags.csv\")\n",
    "links   = pd.read_csv(\"data/links.csv\")\n",
    "movie_genre = pd.read_csv(\"data/movie_genre.csv\")\n",
    "genre = pd.read_csv(\"data/genre.csv\")\n",
    "print(\"ratings\")\n",
    "print(ratings.head())\n",
    "print(\"movies\")\n",
    "print(movies.head())\n",
    "print(\"tags\")\n",
    "print(tags.head())\n",
    "print(\"links\")\n",
    "print(links.head())\n",
    "print(\"movie_genre\")\n",
    "print(movie_genre.head())\n",
    "print(\"genre\")\n",
    "print(genre.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c3dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.sort_values(['userId', 'date', 'time'])\n",
    "\n",
    "N = 4  # number of last ratings per user for test\n",
    "\n",
    "# test = last N per user\n",
    "test  = ratings.groupby('userId', group_keys=False).tail(N)\n",
    "\n",
    "# train = all other ratings\n",
    "train = ratings.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceceb56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.100063219341552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "train_data = Dataset.load_from_df(train[['userId','movieId','rating']], reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "algo = SVD(n_factors=50, reg_all=0.02, lr_all=0.005, random_state=42)\n",
    "algo.fit(trainset)\n",
    "pred = algo.predict(uid=1, iid=2)  # userId=1, movieId=2\n",
    "print(pred.est)  # predicted rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92f1e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9302\n",
      "MAE:  0.7047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.704687826849841"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# convert test DataFrame to surprise format\n",
    "testset = list(test[['userId','movieId','rating']].itertuples(index=False, name=None))\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "rmse(predictions)\n",
    "mae(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8152455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a binary genre matrix: movieId x genre\n",
    "genre_list = genre['genre'].tolist()\n",
    "movie_vec_df = movie_genre.pivot(index='movieId', columns='genre', values='genreId').notna().astype(int)\n",
    "movie_vec_df = movie_vec_df.reindex(columns=genre_list, fill_value=0)  # ensure all genres\n",
    "movie_vec = {mid: movie_vec_df.loc[mid].to_numpy() for mid in movie_vec_df.index}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0af4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_score(uid, iid):\n",
    "    # liked movies: rating >= 4.0\n",
    "    liked = train[(train.userId==uid) & (train.rating>=4.0)]['movieId'].tolist()\n",
    "    if not liked or iid not in movie_vec:\n",
    "        return 0.0\n",
    "    user_vec = np.mean([movie_vec[m] for m in liked if m in movie_vec], axis=0)\n",
    "    return float(np.dot(user_vec, movie_vec.get(iid, np.zeros_like(user_vec))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1817f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f7e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_score(uid, iid, alpha=0.7):\n",
    "    svd_score = algo.predict(uid, iid).est\n",
    "    c_score = content_score(uid, iid)\n",
    "    return alpha * svd_score + (1-alpha) * c_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd6656e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs (svd): 100%|██████████| 610/610 [00:24<00:00, 24.68it/s]\n",
      "Generating Top-K Recs (hybrid): 100%|██████████| 610/610 [00:36<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD — Prec@10: 0.007213, Rec@10: 0.018033, NDCG@10: 0.016093, MAP@10: 0.008246, Coverage: 0.005, ILD: 0.783, Novelty: 7.320\n",
      "Hybrid — Prec@10: 0.007213, Rec@10: 0.018033, NDCG@10: 0.013244, MAP@10: 0.006002, Coverage: 0.013, ILD: 0.452, Novelty: 7.335\n"
     ]
    }
   ],
   "source": [
    "# REPLACE your prior block with this one\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "# --- assumptions (same as before) ---\n",
    "# train, test: DataFrames with columns userId, movieId, rating\n",
    "# movie_ids: np.array of all movieIds in consistent order with genre_matrix\n",
    "# genre_matrix: np.array shape (num_movies, num_genres) matching movie_ids order\n",
    "# user_genre_vec: dict {userId: user_genre_vector} (can be empty)\n",
    "# train_seen: dict {userId: set(movieId)} already prepared\n",
    "# alpha: hybrid weight (e.g. 0.7)\n",
    "# K: Top-K (e.g. 10)\n",
    "\n",
    "# ---------- 1) retrain SVD with best params ----------\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(train[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Best params you found\n",
    "best_params = {'n_factors': 20, 'lr_all': 0.005, 'reg_all': 0.05}\n",
    "algo = SVD(n_factors=best_params['n_factors'],\n",
    "           lr_all=best_params['lr_all'],\n",
    "           reg_all=best_params['reg_all'],\n",
    "           random_state=42)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# ---------- 2) prepare mappings and SVD internals for vectorized scoring ----------\n",
    "trainset = algo.trainset  # surprise internal trainset reference\n",
    "global_mean = trainset.global_mean\n",
    "\n",
    "# map raw item id -> inner id (only items in trainset)\n",
    "raw_to_inner = {}\n",
    "for inner_i in range(trainset.n_items):\n",
    "    raw_i = trainset.to_raw_iid(inner_i)\n",
    "    try:\n",
    "        raw_to_inner[int(raw_i)] = inner_i\n",
    "    except:\n",
    "        raw_to_inner[raw_i] = inner_i\n",
    "\n",
    "qi = algo.qi            # item-factor matrix shape (n_items, n_factors)\n",
    "bi = algo.bi            # item biases shape (n_items,)\n",
    "# algo.pu, algo.bu are user factors / biases for users in trainset\n",
    "\n",
    "# make movie_index_map for genre_matrix lookups (movie_ids -> row index)\n",
    "movie_index_map = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "\n",
    "# default user genre vector\n",
    "default_user_vec = np.mean(list(user_genre_vec.values()), axis=0) if user_genre_vec else np.zeros(genre_matrix.shape[1])\n",
    "\n",
    "# ---------- helper: compute vectorized SVD scores for a user (only for items in trainset) ----------\n",
    "def svd_scores_for_user(raw_uid):\n",
    "    \"\"\"\n",
    "    Returns a dict: raw_item_id -> svd_score for items that exist in trainset.\n",
    "    If user not in trainset, returns item scores = global_mean + bi (no user factors).\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    try:\n",
    "        inner_uid = trainset.to_inner_uid(str(raw_uid))  # convert raw -> inner uid\n",
    "        pu = algo.pu[inner_uid]      # user factors\n",
    "        bu = algo.bu[inner_uid]      # user bias\n",
    "        # vectorized score for all inner items: global + bu + bi + qi.dot(pu)\n",
    "        vec_scores = global_mean + bu + bi + qi.dot(pu)   # shape (n_items,)\n",
    "    except ValueError:\n",
    "        # cold user (no factors in trainset) -> use global_mean + bi (item bias only)\n",
    "        vec_scores = global_mean + bi\n",
    "\n",
    "    # map inner indices back to raw ids and return dict for quick lookup\n",
    "    for inner_i in range(trainset.n_items):\n",
    "        raw_i = trainset.to_raw_iid(inner_i)\n",
    "        try:\n",
    "            raw_id = int(raw_i)\n",
    "        except:\n",
    "            raw_id = raw_i\n",
    "        scores[raw_id] = float(vec_scores[inner_i])\n",
    "    return scores\n",
    "\n",
    "# ---------- content score function (vectorized lookup) ----------\n",
    "def content_score(uid, iid):\n",
    "    u_vec = user_genre_vec.get(uid, default_user_vec)\n",
    "    idx = movie_index_map.get(iid, None)\n",
    "    return float(genre_matrix[idx] @ u_vec) if idx is not None else 0.0\n",
    "\n",
    "# ---------- Top-K generator using vectorized SVD scores per user ----------\n",
    "def get_topk_vectorized(users, mode='svd', K=10):\n",
    "    \"\"\"\n",
    "    mode: 'svd' or 'hybrid'\n",
    "    returns: dict userId -> list of top-K raw movieIds\n",
    "    \"\"\"\n",
    "    recs = {}\n",
    "    for uid in tqdm(users, desc=f\"Generating Top-K Recs ({mode})\"):\n",
    "        seen = train_seen.get(uid, set())\n",
    "        # candidate movie ids (raw ids)\n",
    "        candidates = [mid for mid in movie_ids if mid not in seen]\n",
    "        if not candidates:\n",
    "            recs[uid] = []\n",
    "            continue\n",
    "\n",
    "        # get vectorized SVD scores dict for this user (fast)\n",
    "        svd_dict = svd_scores_for_user(uid)\n",
    "\n",
    "        # build score arrays\n",
    "        svd_scores = np.array([svd_dict.get(int(mid), svd_dict.get(mid, global_mean)) for mid in candidates], dtype=float)\n",
    "        if mode == 'svd':\n",
    "            combined_scores = svd_scores\n",
    "        else:\n",
    "            # compute content scores vectorized\n",
    "            u_vec = user_genre_vec.get(uid, default_user_vec)\n",
    "            # map candidates to genre_matrix rows\n",
    "            cand_idxs = [movie_index_map.get(mid, None) for mid in candidates]\n",
    "            # handle missing indices\n",
    "            valid = [i for i,ci in enumerate(cand_idxs) if ci is not None]\n",
    "            c_scores = np.zeros(len(candidates), dtype=float)\n",
    "            if valid:\n",
    "                rows = genre_matrix[[cand_idxs[i] for i in valid]]\n",
    "                c_scores_valid = rows @ u_vec\n",
    "                for vi, val in zip(valid, c_scores_valid):\n",
    "                    c_scores[vi] = float(val)\n",
    "            combined_scores = alpha * svd_scores + (1 - alpha) * c_scores\n",
    "\n",
    "        top_idx = np.argsort(combined_scores)[-K:][::-1]\n",
    "        recs[uid] = [candidates[i] for i in top_idx]\n",
    "    return recs\n",
    "\n",
    "# ---------- metrics (unchanged) ----------\n",
    "def precision_recall_at_k(recs, test_gt, K=10):\n",
    "    precisions, recalls = [], []\n",
    "    for uid, pred in recs.items():\n",
    "        gt = test_gt.get(uid, set())\n",
    "        if not gt: continue\n",
    "        hits = sum(1 for i in pred if i in gt)\n",
    "        precisions.append(hits/K)\n",
    "        recalls.append(hits/min(len(gt), K))\n",
    "    return np.mean(precisions) if precisions else 0.0, np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "def apk(actual_set, pred_list, K=10):\n",
    "    if not actual_set: return 0.0\n",
    "    score, hits = 0.0, 0\n",
    "    for i, p in enumerate(pred_list[:K], start=1):\n",
    "        if p in actual_set:\n",
    "            hits += 1\n",
    "            score += hits/i\n",
    "    return score / min(len(actual_set), K)\n",
    "\n",
    "def map_at_k(recs, test_gt, K=10):\n",
    "    return np.mean([apk(test_gt.get(uid, set()), pred, K) for uid, pred in recs.items()]) if recs else 0.0\n",
    "\n",
    "def ndcg_at_k(recs, test_gt, K=10):\n",
    "    ndcgs = []\n",
    "    for uid, pred in recs.items():\n",
    "        gt = test_gt.get(uid, set())\n",
    "        if not gt: continue\n",
    "        dcg = sum((1 if p in gt else 0)/math.log2(i+1) for i,p in enumerate(pred[:K], start=1))\n",
    "        idcg = sum(1/math.log2(i+1) for i in range(1, min(len(gt), K)+1))\n",
    "        ndcgs.append(dcg/idcg if idcg>0 else 0.0)\n",
    "    return np.mean(ndcgs) if ndcgs else 0.0\n",
    "\n",
    "def catalog_coverage(recs, all_items): return len(set(x for r in recs.values() for x in r)) / len(all_items)\n",
    "\n",
    "def ild(recs, genre_matrix, movie_index_map):\n",
    "    vals=[]\n",
    "    for rec in recs.values():\n",
    "        if len(rec)<2: continue\n",
    "        idxs = [movie_index_map[i] for i in rec if i in movie_index_map]\n",
    "        if len(idxs) < 2: continue\n",
    "        sims = cosine_similarity(genre_matrix[idxs])\n",
    "        pairs = [1-sims[i,j] for i in range(len(sims)) for j in range(i+1,len(sims))]\n",
    "        if pairs: vals.append(np.mean(pairs))\n",
    "    return np.mean(vals) if vals else 0.0\n",
    "\n",
    "def novelty(recs, train):\n",
    "    pop = train['movieId'].value_counts().to_dict()\n",
    "    total = len(train)\n",
    "    scores=[]\n",
    "    for rec in recs.values():\n",
    "        if not rec: continue\n",
    "        scores.append(np.mean([-math.log(max(pop.get(mid,1e-9)/total,1e-9)) for mid in rec]))\n",
    "    return np.mean(scores) if scores else 0.0\n",
    "\n",
    "# ---------- prepare test_gt and users ----------\n",
    "test_gt = test.groupby('userId')['movieId'].apply(set).to_dict()\n",
    "users = list(test_gt.keys())\n",
    "\n",
    "# ---------- run evaluation ----------\n",
    "svd_recs = get_topk_vectorized(users, mode='svd', K=K)\n",
    "hybrid_recs = get_topk_vectorized(users, mode='hybrid', K=K)\n",
    "\n",
    "for name, recs in [(\"SVD\", svd_recs), (\"Hybrid\", hybrid_recs)]:\n",
    "    p,r = precision_recall_at_k(recs, test_gt, K)\n",
    "    ndcg = ndcg_at_k(recs, test_gt, K)\n",
    "    mAP = map_at_k(recs, test_gt, K)\n",
    "    cov = catalog_coverage(recs, movie_ids)\n",
    "    div = ild(recs, genre_matrix, movie_index_map)\n",
    "    nov = novelty(recs, train)\n",
    "    print(f\"{name} — Prec@{K}: {p:.6f}, Rec@{K}: {r:.6f}, NDCG@{K}: {ndcg:.6f}, MAP@{K}: {mAP:.6f}, Coverage: {cov:.3f}, ILD: {div:.3f}, Novelty: {nov:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca2c327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 20, 'lr_all': 0.005, 'reg_all': 0.05}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "reader = Reader(rating_scale=(0.5,5.0))\n",
    "data = Dataset.load_from_df(train[['userId','movieId','rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "  'n_factors': [20,50,100],\n",
    "  'lr_all': [0.002, 0.005],\n",
    "  'reg_all':[0.02, 0.05, 0.1]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse','mae'], cv=3, n_jobs=4)\n",
    "gs.fit(data)\n",
    "print(gs.best_params['rmse'])\n",
    "# then train final algo with gs.best_params['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21ee4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trainset = algo.trainset\n",
    "global_mean = trainset.global_mean\n",
    "\n",
    "def vectorized_svd_scores_for_user(raw_uid):\n",
    "    try:\n",
    "        iu = trainset.to_inner_uid(str(raw_uid))\n",
    "    except ValueError:\n",
    "        return None  # cold user\n",
    "    pu = algo.pu[iu]          # user factors\n",
    "    bu = algo.bu[iu]          # user bias\n",
    "    # item factors/ biases for all items in trainset\n",
    "    qi = algo.qi              # shape (n_items, n_factors)\n",
    "    bi = algo.bi              # shape (n_items,)\n",
    "    scores = global_mean + bu + bi + qi.dot(pu)\n",
    "    # map inner item ids -> raw ids\n",
    "    raw_items = np.array([trainset.to_raw_iid(i) for i in range(trainset.n_items)], dtype=int)\n",
    "    return raw_items, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ff56e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search over alpha for hybrid weighting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [02:59<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.0 — Prec@10: 0.001639, Rec@10: 0.004098, NDCG@10: 0.003428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [03:06<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1 — Prec@10: 0.001639, Rec@10: 0.004098, NDCG@10: 0.003803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [02:54<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.2 — Prec@10: 0.002295, Rec@10: 0.005738, NDCG@10: 0.004947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [02:58<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.3 — Prec@10: 0.003607, Rec@10: 0.009016, NDCG@10: 0.008153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [03:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.4 — Prec@10: 0.005082, Rec@10: 0.012705, NDCG@10: 0.011213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [03:13<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.5 — Prec@10: 0.006066, Rec@10: 0.015164, NDCG@10: 0.013294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [03:15<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.6 — Prec@10: 0.007213, Rec@10: 0.018033, NDCG@10: 0.013719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [13:38:25<00:00, 80.50s/it]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.7 — Prec@10: 0.007213, Rec@10: 0.018033, NDCG@10: 0.013076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [02:17<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.8 — Prec@10: 0.007213, Rec@10: 0.018033, NDCG@10: 0.013646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [02:44<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.9 — Prec@10: 0.006885, Rec@10: 0.017213, NDCG@10: 0.013115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Recs: 100%|██████████| 610/610 [02:43<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1.0 — Prec@10: 0.006885, Rec@10: 0.017213, NDCG@10: 0.013412\n",
      "\n",
      "Best alpha: 0.6 — Prec@10: 0.007213, Rec@10: 0.018033, NDCG@10: 0.013719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Range of alpha values to test (SVD weight)\n",
    "alpha_values = np.linspace(0, 1, 11)  # 0.0, 0.1, ..., 1.0\n",
    "results = []\n",
    "\n",
    "print(\"Grid search over alpha for hybrid weighting:\")\n",
    "\n",
    "for a in alpha_values:\n",
    "    alpha = a  # update global alpha used in hybrid_score\n",
    "    hybrid_recs = get_topk(users, hybrid_score, K)\n",
    "    p,r = precision_recall_at_k(hybrid_recs, test_gt, K)\n",
    "    ndcg = ndcg_at_k(hybrid_recs, test_gt, K)\n",
    "    results.append((alpha, p, r, ndcg))\n",
    "    print(f\"alpha={alpha:.1f} — Prec@{K}: {p:.6f}, Rec@{K}: {r:.6f}, NDCG@{K}: {ndcg:.6f}\")\n",
    "\n",
    "# Find best alpha based on Precision@K\n",
    "best_alpha, best_prec, best_rec, best_ndcg = max(results, key=lambda x: x[1])\n",
    "print(f\"\\nBest alpha: {best_alpha:.1f} — Prec@{K}: {best_prec:.6f}, Rec@{K}: {best_rec:.6f}, NDCG@{K}: {best_ndcg:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
